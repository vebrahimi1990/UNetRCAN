{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tv4sbUfUXbVa",
    "outputId": "22b0628c-936e-4643-ac9a-d8bbb031c17e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "#         tf.config.set_logical_device_configuration(\n",
    "#             gpus[0],\n",
    "#             [tf.config.LogicalDeviceConfiguration(memory_limit=10000)])\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tifffile import imsave, imread, imwrite\n",
    "from keras.models import Input, Model\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau,LearningRateScheduler\n",
    "from tifffile import imwrite\n",
    "\n",
    "from datagenerator_2D import data_generator\n",
    "# from model_2D_interconnect import make_generator\n",
    "from Model_2D_Unet import make_generator\n",
    "from loss_2D import generator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1, 2048, 2048)\n",
      "16\n",
      "The training set shape is: (16, 2048, 2048, 1)\n",
      "The validation set shape is: (0, 2048, 2048, 1)\n"
     ]
    }
   ],
   "source": [
    "GT_image_dr = r'D:\\Models\\Data generator\\corssmodality-deconvolution\\fast sted\\train\\Average.tif'\n",
    "lowSNR_image_dr =r'D:\\Models\\Data generator\\corssmodality-deconvolution\\fast sted\\train\\1frame.tif'\n",
    "\n",
    "patch_size = 2048\n",
    "n_patches = 1\n",
    "n_channel =  0\n",
    "add_noise = False\n",
    "\n",
    "x_test, y_test,_,_ = data_generator(GT_image_dr, lowSNR_image_dr, patch_size, n_patches,\n",
    "                                                    n_channel, threshold =0 ,ratio=1.0,lp=0.4, augment=False, shuffle=False,\n",
    "                                   add_noise=add_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = random.sample(range(len(x_test)),4)\n",
    "fig = plt.figure(figsize=(15,7))\n",
    "\n",
    "for i in range(4):\n",
    "    fig.add_subplot(2,4, 2*i+1)\n",
    "    cmap=plt.get_cmap('magma')\n",
    "    plt.imshow(x_test[ix[i],:,:,0].squeeze(),cmap)\n",
    "    plt.title('Low SNR',fontdict={'fontsize':18})\n",
    "    plt_axis = plt.axis('off')\n",
    "\n",
    "    fig.add_subplot(2,4, 2*i+2)\n",
    "    cmap=plt.get_cmap('magma')\n",
    "    plt.imshow(y_test[ix[i],:,:,0].squeeze(),cmap)\n",
    "    plt.title('High SNR',fontdict={'fontsize':18})\n",
    "    plt_axis = plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"conv2d_40\" (type Conv2D).\n\nOOM when allocating tensor with shape[1,80,2048,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(1, 2048, 2048, 80), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m prediction2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(x_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x_test)):\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#     prediction1[i],prediction2[i]= generator(x_test[i:i+1],training=False)\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     prediction2[i] \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#     prediction1[i] = prediction1[i]/prediction1[i].max()\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     prediction2[i] \u001b[38;5;241m=\u001b[39m prediction2[i]\u001b[38;5;241m/\u001b[39mprediction2[i]\u001b[38;5;241m.\u001b[39mmax()\n",
      "File \u001b[1;32mc:\\users\\va332845\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\users\\va332845\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7107\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7106\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7107\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"conv2d_40\" (type Conv2D).\n\nOOM when allocating tensor with shape[1,80,2048,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(1, 2048, 2048, 80), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model_save_directory = r\"D:\\Models\\Data generator\\corssmodality-deconvolution\\fast sted\\histon_1.h5\" \n",
    "\n",
    "\n",
    "filters =[80,160,320,640]\n",
    "num_filters = filters[0]\n",
    "filters_cab=num_filters/16\n",
    "num_RG=3\n",
    "num_RCAB=8\n",
    "\n",
    "generator_input = Input((patch_size, patch_size,1))\n",
    "generator = make_generator(generator_input, filters, num_filters,filters_cab,num_RG,num_RCAB,\n",
    "                           kernel_shape=3,dropout=0.2)\n",
    "generator.load_weights(model_save_directory)\n",
    "\n",
    "prediction1 = np.zeros(x_test.shape)\n",
    "prediction2 = np.zeros(x_test.shape)\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "#     prediction1[i],prediction2[i]= generator(x_test[i:i+1],training=False)\n",
    "    prediction2[i] = generator(x_test[i:i+1],training=False)\n",
    "#     prediction1[i] = prediction1[i]/prediction1[i].max()\n",
    "    prediction2[i] = prediction2[i]/prediction2[i].max()\n",
    "# prediction1 = prediction1/prediction1.max()\n",
    "# prediction2= prediction2/prediction2.max()\n",
    "prediction1[prediction1<0]=0\n",
    "prediction2[prediction2<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "Pl6pCBtNFOko",
    "outputId": "24ecab5f-9ec0-4bd7-8e1d-51ca3bbb8ed3"
   },
   "outputs": [],
   "source": [
    "ix = np.random.randint(len(prediction1))\n",
    "# ix = 0\n",
    "fig = plt.figure(figsize=(40,40))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(x_test[ix, :, :, 0] , cmap='magma')\n",
    "plt.title('Low SNR Input',fontdict={'fontsize':20})\n",
    "plt_axis = plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(prediction1[ix, :, :, 0] , cmap='magma')\n",
    "plt.title('Prediction by UNet',fontdict={'fontsize':20})\n",
    "plt_axis = plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(prediction2[ix, :, :, 0] , cmap='magma')\n",
    "plt.title('Prediction by RCAN',fontdict={'fontsize':20})\n",
    "plt_axis = plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(y_test[ix, :, :, 0] , cmap='magma')\n",
    "plt.title('Ground Truth',fontdict={'fontsize':20})\n",
    "plt_axis = plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "jsmkGppEzXTd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_image_dr = r\"D:\\Models\\Data generator\\corssmodality-deconvolution\\fast sted\\results\" \n",
    "\n",
    "# pred1_test = np.moveaxis(prediction1,3,1)\n",
    "# pred2_test = np.moveaxis(prediction2,3,1)\n",
    "# X_test = np.moveaxis(x_test,3,1)\n",
    "# Y_test = np.moveaxis(y_test,3,1)\n",
    "\n",
    "\n",
    "pred1_test = prediction1*(2**16-1)\n",
    "pred2_test = prediction2*(2**16-1)\n",
    "X_test = x_test*(2**16-1)\n",
    "Y_test = y_test*(2**16-1)\n",
    "\n",
    "pred1_test = pred1_test.astype(np.uint16)\n",
    "pred2_test = pred2_test.astype(np.uint16)\n",
    "\n",
    "X_test = X_test.astype(np.uint16)\n",
    "Y_test = Y_test.astype(np.uint16)\n",
    "\n",
    "imwrite(save_image_dr+'/pred1_t2.tif', pred1_test.squeeze(),imagej=True,metadata={'axes': 'TYX'})\n",
    "imwrite(save_image_dr+'/pred2_t2.tif', pred2_test.squeeze(),imagej=True,metadata={'axes': 'TYX'})\n",
    "\n",
    "imwrite(save_image_dr+'/noisy_t1.tif', X_test.squeeze(),imagej=True,metadata={'axes': 'TYX'})\n",
    "imwrite(save_image_dr+'/gt_t1.tif', Y_test.squeeze(),imagej=True,metadata={'axes': 'TYX'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "tJ-bKyN3iyfm",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_parameters_dr = r\"D:\\Models\\Data generator\\Comparing two step with single step prediction\\two\\param2.csv\"\n",
    "\n",
    "def norm_mse(prediction, gt):\n",
    "    mse = tf.keras.metrics.mean_squared_error(prediction, gt)\n",
    "    mse = tf.math.reduce_sum(mse, axis=(1, 2))\n",
    "    norm = tf.norm(gt, axis=(1, 2))\n",
    "    norm = tf.squeeze(norm)\n",
    "    norm = tf.pow(norm, 2)\n",
    "    norm = tf.math.reduce_sum(norm)\n",
    "    norm_mse = tf.math.divide(mse, norm)\n",
    "    return norm_mse.numpy()\n",
    "\n",
    "def nmse_psnr_ssim(prediction,gt):\n",
    "    nmse = norm_mse(prediction,gt)\n",
    "    psnr = tf.image.psnr(prediction, gt, max_val = 1.0).numpy()\n",
    "    ssim = tf.image.ssim_multiscale(prediction, gt, max_val = 1.0, filter_size=14,\n",
    "                                    filter_sigma=1.5, k1=0.01, k2=0.03).numpy()\n",
    "    return nmse,psnr,ssim\n",
    "    \n",
    "imageq_param = np.zeros((9,len(prediction1)))\n",
    "\n",
    "imageq_param[0::3,:] = nmse_psnr_ssim(x_test,y_test)\n",
    "imageq_param[1::3,:] = nmse_psnr_ssim(prediction1,y_test)\n",
    "imageq_param[2::3,:] = nmse_psnr_ssim(prediction2,y_test)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "labels = ['noisy', 'prediction1', 'prediction2']\n",
    "\n",
    "bplot1 = axes[0].boxplot([imageq_param[0,:],imageq_param[1,:],imageq_param[2,:]],\n",
    "                         vert=True,  \n",
    "                         patch_artist=True,  \n",
    "                         labels=labels,showfliers=False)  \n",
    "axes[0].set_title('NMSE',fontsize=20)\n",
    "\n",
    "bplot2 = axes[1].boxplot([imageq_param[3,:],imageq_param[4,:],imageq_param[5,:]],\n",
    "                         vert=True,  \n",
    "                         patch_artist=True,  \n",
    "                         labels=labels,showfliers=False)  \n",
    "axes[1].set_title('PSNR',fontsize=20)\n",
    "\n",
    "bplot3 = axes[2].boxplot([imageq_param[6,:],imageq_param[7,:],imageq_param[8,:]],\n",
    "                         vert=True,  \n",
    "                         patch_artist=True,  \n",
    "                         labels=labels,showfliers=False)  \n",
    "cc= axes[2].set_title('MS-SSIM',fontsize=20)\n",
    "\n",
    "\n",
    "# np.savetxt(save_parameters_dr, np.transpose(imageq_param), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Denoising_UNET_RCAN_3D.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
